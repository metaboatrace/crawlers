import argparse
from datetime import datetime, timedelta
from time import sleep

from metaboatrace.models.stadium import EventHoldingStatus
from metaboatrace.scrapers.official.website.exceptions import DataNotFound, RaceCanceled
from tqdm import tqdm

from metaboatrace.crawlers.exceptions import IncompleteDataError, RaceDeadlineChanged
from metaboatrace.crawlers.official.website.v1707.race import (
    crawl_race_before_information_page,
    crawl_race_information_page,
    crawl_race_result_page,
    crawl_trifecta_odds_page,
)
from metaboatrace.crawlers.official.website.v1707.stadium import (
    crawl_event_holding_page,
    crawl_events_from_monthly_schedule_page,
    crawl_pre_inspection_information_page,
)
from metaboatrace.repositories import RaceRepository
from metaboatrace.crawlers.utils import send_slack_notification


def _valid_end_date(s: str) -> datetime.date:
    try:
        end_date = datetime.strptime(s, "%Y-%m-%d").date()
        if end_date >= datetime.now().date():
            raise argparse.ArgumentTypeError("end_date ã¯æœ¬æ—¥ä»¥å‰ã®æ—¥ä»˜ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        return end_date
    except ValueError:
        raise argparse.ArgumentTypeError("ä¸æ­£ãªæ—¥ä»˜å½¢å¼ã§ã™ã€‚YYYY-MM-DD å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹æœŸé–“ã‚’æŒ‡å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚")
    parser.add_argument(
        "start_date",
        type=lambda s: datetime.strptime(s, "%Y-%m-%d").date(),
        help="é–‹å§‹æ—¥ (YYYY-MM-DD å½¢å¼)",
    )
    parser.add_argument("end_date", type=_valid_end_date, help="çµ‚äº†æ—¥ (YYYY-MM-DD å½¢å¼)")
    parser.add_argument("--sleep", type=int, default=1, help="ã‚¯ãƒ­ãƒ¼ãƒ«é–“ã®ã‚¹ãƒªãƒ¼ãƒ—æ™‚é–“ (ç§’)")
    return parser.parse_args()


def _main() -> None:
    args = _parse_args()
    start_date = args.start_date
    end_date = args.end_date
    sleep_second = args.sleep

    start_message = f"ğŸš€ Starting data crawl from {start_date} to {end_date}"
    send_slack_notification(start_message)

    try:
        total_days = (end_date - start_date).days + 1

        for day_offset in tqdm(range(total_days), desc="Processing", unit="day"):
            current_date = start_date + timedelta(days=day_offset)
            print(current_date.strftime("%Y-%m-%d"))

            if current_date.day == 1:
                crawl_events_from_monthly_schedule_page(current_date.year, current_date.month)
                print("\tProcessing monthly schedule page.")
                sleep(sleep_second)

            event_holdings = crawl_event_holding_page(current_date)
            will_be_opned_event_holdings = [
                e for e in event_holdings if e.status == EventHoldingStatus.OPEN
            ]
            for e in will_be_opned_event_holdings:
                print(f"\t{e.stadium_tel_code.name} day {e.progress_day}")
                if e.progress_day == 1:
                    try:
                        crawl_pre_inspection_information_page(
                            e.stadium_tel_code.value, current_date
                        )
                        print("\t\tProcessing pre inspection information page.")
                        sleep(sleep_second)
                    except DataNotFound:
                        print(
                            "\t\t\t\033[93m[warn] The pre inspection information page had not found.\033[0m"
                        )

                for race_number in range(1, 13):
                    print(f"\t\tProcessing {race_number}R pages.")
                    try:
                        crawl_functions = [
                            crawl_race_information_page,
                            crawl_race_before_information_page,
                            crawl_race_result_page,
                            crawl_trifecta_odds_page,
                        ]

                        for crawl_function in crawl_functions:
                            try:
                                crawl_function(e.stadium_tel_code.value, current_date, race_number)
                            except IncompleteDataError:
                                print(
                                    "\t\t\t\033[94m[notice] Partial data missing in {function}. Continuing with next task.\033[0m".format(
                                        function=crawl_function.__name__
                                    )
                                )
                            except RaceDeadlineChanged:
                                pass

                            sleep(sleep_second)
                    except RaceCanceled:
                        # HACK: å±•ç¤ºèˆªèµ°ã¾ã§ã¯å®Ÿæ–½ã•ã‚Œã¦ã‚‹ãªã‚‰ãƒ¬ãƒ¼ã‚¹çµæœã‚’ã‚¹ã‚¯ãƒ¬ãƒ”ãƒ³ã‚°ã—ãŸã‚‰ã“ã®ä¾‹å¤–å‡ºã‚‹ã‘ã©
                        # å±•ç¤ºã‚‚å®Ÿæ–½ã•ã‚Œã¦ãªã„ãªã‚‰ ValueError ã¨ã‹ãŒå‡ºã¦ã“ã“ã«åˆ°é”ã—ãªã„ã®ã§ã¯ï¼Ÿ
                        repository = RaceRepository()
                        repository.cancel(e.stadium_tel_code.value, current_date, race_number)
                        print(
                            "\t\t\t\033[90m[info] The race was canceled. Moving to the next event.\033[0m"
                        )
                        break

        success_message = f"âœ… Successfully completed data crawl from {start_date} to {end_date}"
        send_slack_notification(success_message)

    except Exception as e:
        error_message = f"âŒ Error during data crawl from {start_date} to {end_date}: {str(e)}"
        send_slack_notification(error_message)
        raise


if __name__ == "__main__":
    _main()
